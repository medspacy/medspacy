{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In these notebooks, we'll process an example clinical document with medSpaCy. First, we'll perform preprocessing and sentence segmentation. Next, we'll extract entities using rules, assert attributes such as negation and which section the entity occured in. We'll then put all of our pieces together to process the entire document. Finally, we'll look at an alternative pipeline using a pre-trained statistical model to extract target entities rather than rules.\n",
    "\n",
    "In this first notebook, we'll introduce the medSpaCy library and show how to load a medSpaCy pipeline. Then in the following notebooks we'll walk through each of the pipeline steps in more detail and apply a fully built pipeline on clinical text.\n",
    "\n",
    "These notebooks will give a high-level overview of each component, but the individual packages will typically contain more complete examples and documentation. \n",
    "\n",
    "# Notebooks\n",
    "\n",
    "## High-Level Notebooks\n",
    "The notebooks in this root directory will show an overview of medspaCy, how to load a basic pipeline, and the basics of how to use each component. Notebooks #1-3 will show how to use the components loaded in a default medSpaCy model. We'll then show how to add additional medSpaCy components such as section detection and pre/postprocessing. Then we'll show how a full medSpaCy pipeline processes example clinical text, first using custom rules and then using a pre-trained NER model.\n",
    "\n",
    "\n",
    "## Detailed Component Notebooks\n",
    "More detailed notebooks are provided for two of the components: `context` and `section_detection`. These will show more advanced functionality and detailed examples:\n",
    "- `./context/`\n",
    "- `./section_detection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a medSpaCy model\n",
    "A medSpaCy model consists of a **base spaCy model** with **medSpaCy components added** to the pipeline. There are two primary ways that we can create a medSpaCy model:\n",
    "\n",
    "1. Load a full pipeline using `medspacy.load()`\n",
    "2. Add specific components to an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a full medSpaCy pipeline\n",
    "We can load a complete pipeline using the `medspacy.load()` function. By default, this will build off of `spacy.blank(\"en\")` will include:\n",
    "- `medspacy_tokenizer`: A spaCy tokenizer with more aggressive rules for handling clinical text. This will not be visible in the pipeline but is set to `nlp.tokenizer`.\n",
    "- `medspacy_pyrush`: The clinical sentence splitter [PyRuSH](https://github.com/jianlins/PyRuSH)\n",
    "- `medspacy_target_matcher`: For extended rule-based matching\n",
    "- `medspacy_context`: For contextual analysis and attribute detection, an implementation of the ConText algorithm.\n",
    "\n",
    "A large list of components is available, but are not activated by default. Most of these are unnecessary for the most simple pipelines that `medspacy.load()` is designed to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load from an existing model to add medspaCy pipeline components to your current pipeline. To do this, either pass in the model directly or the name of the model. For example, in the examples below we can load spaCy's `\"en_core_web_sm\"` model.\n",
    "\n",
    "Notice at the end of the `nlp.pipe_names` result, we have the default medspacy components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_target_matcher',\n",
       " 'medspacy_context']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = medspacy.load(nlp2)\n",
    "nlp2.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_target_matcher',\n",
       " 'medspacy_context']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2 = medspacy.load(\"en_core_web_sm\")\n",
    "nlp2.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default rules\n",
    "When available, components added by `medspacy.load()` include default rules. `medspacy_context`, and `medspacy_sectionizer` will both contain extensive default rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nlp.get_pipe(\"medspacy_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ConTextRule(literal='absence of', category='NEGATED_EXISTENCE', pattern=None, direction='FORWARD')\n",
      "\n",
      "ConTextRule(literal='adequate to rule out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['adequate', 'sufficient']}}, {'LOWER': 'to'}, {'LOWER': 'rule'}, {'LOWER': {'IN': ['him', 'her', 'them', 'patient', 'pt']}, 'OP': '?'}, {'LOWER': 'out'}, {'LOWER': {'IN': ['against', 'for']}, 'OP': '?'}], direction='FORWARD')\n",
      "\n",
      "ConTextRule(literal='adequate to rule the patient out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['adequate', 'sufficient']}}, {'LOWER': 'to'}, {'LOWER': 'rule'}, {'LOWER': 'the'}, {'LOWER': {'IN': ['patient', 'pt']}}, {'LOWER': 'out'}, {'LOWER': {'IN': ['against', 'for']}, 'OP': '?'}], direction='FORWARD')\n",
      "\n",
      "ConTextRule(literal='any other', category='NEGATED_EXISTENCE', pattern=None, direction='FORWARD')\n",
      "\n",
      "ConTextRule(literal='apart from', category='NEGATED_EXISTENCE', pattern=[{'LOWER': 'apart'}, {'LOWER': {'IN': ['for', 'from']}}], direction='TERMINATE')\n",
      "\n",
      "ConTextRule(literal='are ruled out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['are', 'is', 'was']}}, {'LOWER': 'ruled'}, {'LOWER': 'out'}], direction='BACKWARD')\n",
      "\n",
      "ConTextRule(literal='as a cause for', category='NEGATED_EXISTENCE', pattern=[{'LOWER': 'as'}, {'LOWER': {'IN': ['a', 'an', 'the']}}, {'LOWER': 'secondary', 'OP': '?'}, {'LOWER': {'IN': ['cause', 'etiology', 'source', 'reason']}}, {'LOWER': {'IN': ['for', 'of']}}], direction='TERMINATE')\n",
      "\n",
      "ConTextRule(literal='as has', category='NEGATED_EXISTENCE', pattern=None, direction='TERMINATE')\n",
      "\n",
      "ConTextRule(literal='as needed', category='HYPOTHETICAL', pattern=None, direction='FORWARD')\n",
      "\n",
      "ConTextRule(literal='as well as any', category='NEGATED_EXISTENCE', pattern=None, direction='FORWARD')\n"
     ]
    }
   ],
   "source": [
    "for rule in context.rules[:10]:\n",
    "    print()\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set `load_rules` to `False` so that the components are all blank (other than PyRuSH, which requires rules to be instantiated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using specific models\n",
    "If you have other models installed, either in English or other languages, you can load that model in using the `model` argument. For example, to load a [sciSpaCy model](https://allenai.github.io/scispacy/) and use it with medSpaCy, first download the model:\n",
    "\n",
    "```bash\n",
    "pip install scispacy\n",
    "pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_sm-0.5.3.tar.gz\n",
    "```\n",
    "The actual version of model will be changed depends on which version of spaCy you have. Check the compatibilty of versions between sciSpaCy and spaCy [here](https://github.com/allenai/scispacy/releases), and then load it with medSpaCy:\n",
    "\n",
    "```python\n",
    "nlp = medspacy.load(\"en_core_sci_sm\", load_rules=False, medspacy_disable=[\"medspacy_target_matcher\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_context']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = medspacy.load(\"en_core_web_sm\", load_rules=False, medspacy_disable=[\"medspacy_target_matcher\"])\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send in keyword arguments to the spacy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'medspacy_target_matcher']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = medspacy.load(\"en_core_web_sm\", medspacy_enable=[\"medspacy_target_matcher\"], **{\"disable\": [\"ner\"]})\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying components\n",
    "You can define which specific components to include or specific components to exclude through the `medspacy_enable` and `medspacy_disable` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only load the default components\n",
    "nlp_default = medspacy.load()\n",
    "nlp_default.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context', 'medspacy_sectionizer', 'medspacy_postprocessor', 'medspacy_doc_consumer']\n",
      "<medspacy.preprocess.preprocessor.Preprocessor object at 0x7feae10879d0>\n"
     ]
    }
   ],
   "source": [
    "# All medspaCy components\n",
    "nlp_full = medspacy.load(medspacy_enable=\"all\")\n",
    "print(nlp_full.pipe_names)\n",
    "# a preprocessor that includes medspacy's tokenizer is set to the tokenizer when enabling \"all\"\n",
    "print(nlp_full.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable only some components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medspacy_target_matcher', 'medspacy_context']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only load the context and target matcher\n",
    "nlp_matcher_only = medspacy.load(medspacy_enable=[\"medspacy_context\", \"medspacy_target_matcher\"])\n",
    "nlp_matcher_only.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable some components but load others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medspacy_target_matcher']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable pyrush and context\n",
    "nlp_no_pyrush_context = medspacy.load(medspacy_enable=\"default\", medspacy_disable=[\"medspacy_pyrush\", \"medspacy_context\"])\n",
    "nlp_no_pyrush_context.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add specific components to an existing model\n",
    "You can also add medspacy components to a pipeline without needing to use `medspacy.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<medspacy.context.context.ConText at 0x7fead3586a30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.add_pipe(\"medspacy_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_context']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.pipe_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
