{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In these notebooks, we'll process an example clinical document with medSpaCy. First, we'll perform preprocessing and sentence segmentation. Next, we'll extract entities using rules, assert attributes such as negation and which section the entity occured in. We'll then put all of our pieces together to process the entire document. Finally, we'll look at an alternative pipeline using a pre-trained statistical model to extract target entities rather than rules.\n",
    "\n",
    "In this first notebook, we'll introduce the medSpaCy library and show how to load a medSpaCy pipeline. Then in the following notebooks we'll walk through each of the pipeline steps in more detail and apply a fully built pipeline on clinical text.\n",
    "\n",
    "These notebooks will give a high-level overview of each component, but the individual packages will typically contain more complete examples and documentation. \n",
    "\n",
    "**Disclaimer**: many of the subpackages are in beta, just like medSpaCy!\n",
    "\n",
    "# Notebooks\n",
    "- [1-Introduction](1-Introduction.ipynb)\n",
    "- [2-Preprocessing_and_Sentence_Splitting](2-Preprocessing_and_Sentence_Splitting.ipynb)\n",
    "- [3-Information-Extraction](3-Information-Extraction.ipynb)\n",
    "- [4-Full-Pipeline](4-Full-Pipeline.ipynb)\n",
    "- [5-Using-Pretrained-Models](5-Using-Pretrained-Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a medSpaCy model\n",
    "A medSpaCy model consists of a **base spaCy model** with **medSpaCy components added** to the pipeline. There are two primary ways that we can create a medSpaCy model:\n",
    "\n",
    "1. Load a full pipeline using `medspacy.load()`\n",
    "2. Add specific components to an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a full medSpaCy pipeline\n",
    "We can load a complete pipeline using the `medspacy.load()` function. By default, this will build off of spaCy's **en_core_web_sm** model and will include:\n",
    "- `Preprocessor` for destructive preprocessing\n",
    "- `Tagger`: A part-of-speech tagger (from **en_core_web_sm**)\n",
    "- `Parser`: A dependency parser (from **en_core_web_sm**)\n",
    "- `TargetMatcher` for extended rule-based matching\n",
    "- `Sectionizer` for section detection\n",
    "- `ConText` for contextual analysis and attribute detection\n",
    "- `Postprocessor` for additional business logic and custom rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'parser',\n",
       " 'target_matcher',\n",
       " 'sectionizer',\n",
       " 'context',\n",
       " 'postprocessor']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default rules\n",
    "When available, components added by `medspacy.load()` include default rules. `Context`, and `sectionizer` will both contain default rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nlp.get_pipe(\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConTextItem(literal='absence of', category='NEGATED_EXISTENCE', pattern=None, rule='FORWARD'),\n",
       " ConTextItem(literal='adequate to rule out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['adequate', 'sufficient']}}, {'LOWER': 'to'}, {'LOWER': 'rule'}, {'LOWER': {'IN': ['him', 'her', 'them', 'patient', 'pt']}, 'OP': '?'}, {'LOWER': 'out'}, {'LOWER': {'IN': ['against', 'for']}, 'OP': '?'}], rule='FORWARD'),\n",
       " ConTextItem(literal='adequate to rule the patient out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['adequate', 'sufficient']}}, {'LOWER': 'to'}, {'LOWER': 'rule'}, {'LOWER': 'the'}, {'LOWER': {'IN': ['patient', 'pt']}}, {'LOWER': 'out'}, {'LOWER': {'IN': ['against', 'for']}, 'OP': '?'}], rule='FORWARD'),\n",
       " ConTextItem(literal='any other', category='NEGATED_EXISTENCE', pattern=None, rule='FORWARD'),\n",
       " ConTextItem(literal='apart from', category='NEGATED_EXISTENCE', pattern=[{'LOWER': 'apart'}, {'LOWER': {'IN': ['for', 'from']}}], rule='TERMINATE'),\n",
       " ConTextItem(literal='are ruled out', category='NEGATED_EXISTENCE', pattern=[{'LOWER': {'IN': ['are', 'is', 'was']}}, {'LOWER': 'ruled'}, {'LOWER': 'out'}], rule='BACKWARD'),\n",
       " ConTextItem(literal='as a cause for', category='NEGATED_EXISTENCE', pattern=[{'LOWER': 'as'}, {'LOWER': {'IN': ['a', 'an', 'the']}}, {'LOWER': 'secondary', 'OP': '?'}, {'LOWER': {'IN': ['cause', 'etiology', 'source', 'reason']}}, {'LOWER': {'IN': ['for', 'of']}}], rule='TERMINATE'),\n",
       " ConTextItem(literal='as has', category='NEGATED_EXISTENCE', pattern=None, rule='TERMINATE'),\n",
       " ConTextItem(literal='as needed', category='HYPOTHETICAL', pattern=None, rule='FORWARD'),\n",
       " ConTextItem(literal='as well as any', category='NEGATED_EXISTENCE', pattern=None, rule='FORWARD')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.item_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionizer = nlp.get_pipe(\"sectionizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'section_title': 'addendum', 'pattern': 'ADDENDUM:'},\n",
       " {'section_title': 'addendum', 'pattern': 'Addendum:'},\n",
       " {'section_title': 'allergies', 'pattern': 'ALLERGIC REACTIONS:'},\n",
       " {'section_title': 'allergies', 'pattern': 'ALLERGIES:'},\n",
       " {'section_title': 'chief_complaint', 'pattern': 'CC:'},\n",
       " {'section_title': 'chief_complaint', 'pattern': 'CHIEF COMPLAINT:'},\n",
       " {'section_title': 'chief_complaint', 'pattern': 'Chief Complaint:'},\n",
       " {'section_title': 'comments', 'pattern': 'COMMENTS:'},\n",
       " {'section_title': 'diagnoses', 'pattern': 'ADMISSION DIAGNOSES:'},\n",
       " {'section_title': 'diagnoses', 'pattern': 'DIAGNOSES:'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectionizer.patterns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set `load_rules` to `False` so that the components are all blank (other than PyRuSH, which requires rules to be instantiated):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using specific models\n",
    "If you have other models installed, either in English or other languages, you can load that model in using the `model` argument. For example, to load a German model, first download the model:\n",
    "\n",
    "`python -m spacy download de_core_news_sm`\n",
    "\n",
    "```python\n",
    "de = medspacy.load(\"de_core_news_sm\", load_rules=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying components\n",
    "You can define which specific components to include or specific components to exclude through the `enable` and `disable` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sectionizer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sectionizer_only = medspacy.load(enable=[\"sectionizer\"])\n",
    "nlp_sectionizer_only.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_matcher', 'sectionizer', 'context', 'postprocessor']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_no_pos_dep = medspacy.load(disable=[\"tagger\", \"parser\"])\n",
    "nlp_no_pos_dep.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add specific components to an existing model\n",
    "You can also import specific classes from medSpaCy, instantiate them yourself, and add them to an existing model. We'll show more examples of how to do this in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medspacy.context import ConTextComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en.add_pipe(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'context']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Data\n",
    "For data, we will use this example text derived from the [MIMIC-II](https://mimic.physionet.org/) critical care dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./discharge_summary.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission Date:  [**2573-5-30**]              Discharge Date:   [**2573-7-1**]\n",
      "\n",
      "Date of Birth:  [**2498-8-19**]             Sex:   F\n",
      "\n",
      "Service: SURGERY\n",
      "\n",
      "Allergies:\n",
      "Hydrochlorothiazide\n",
      "\n",
      "Attending:[**First Name3 (LF) 1893**]\n",
      "Chief Complaint:\n",
      "Abdominal pain\n",
      "\n",
      "Major Surgical or Invasive Procedure:\n",
      "PICC line [**6-25**]\n",
      "ERCP w/ sphincterotomy [**5-31**]\n",
      "\n",
      "\n",
      "History of Present Illness:\n",
      "74y female with type 2 dm and a recent stroke affecting her\n",
      "speech, who presents with 2 days of abdominal pain. Imaging sh\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
